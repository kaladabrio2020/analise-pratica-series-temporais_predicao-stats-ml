---
title: "R Notebook"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

```{r}
require(data.table)
require(zoo)
require(forecast)
```

## Revisando Self-Correlation

É a ideia de que um valor em uma série temporal em um determinado ponto o tempo pode estar correlacionada com em outro ponto no tempo.

> **Ex de self-correlation :** seria compararmos uma série temporal anual de dados diarios de temperatura o dia 15 maio de cada ano com o dia 15 de agosto de cada ano, e descobrirmos que os dias 15 de maio amis quentes tendem se correlacionar com os dias 15 de agosto mais quentes.

### Função de autocorrelação (A.C.F)

Dá uma ideia de como os pontos de dados em diferentes pontos no tempo estão linearmente relacionados entre si em uma função de sua diferença de tempo.

```{r}
x = 1:100
y = sin (x * pi/3)
plot(y, type = 'b')
```

```{r}
acf(y)
```

> Os pontos de com uma defasagem de 0 periodo (**lag**) tem uma correlação de 1, enquanto os pontos separados por defasagem de 1 periodo tem uma correlação de 0.5. Os pontos separados por desfasagem de 2 periodos tem uma correlação de -0.5 e assim por diante....

```{r}
# Exemplo de calculo no r

vetor_ = c()
for (lags_ in 0:10){
  vetor_ = append(
    vetor_, cor(y, shift(y, n = lags_ , type = "lag"), use = "pairwise.complete.obs")
    )
}

data.frame( lag = 0:10, correlacao = vetor_)
```

```{r}
1.96 * sqrt(100)
```

### Função de autocorrelação parcial

A autocorrelação de uma serie temporal para um determinda defasagem é a correlação parcial dessa série temporal com ela mesma nessa defasagem dada todas as informações entre os dois pontos.

```{r}
pacf(y)
```

> Pacf mostra quais pontos de dados são mais informativos e quais são os pontos harmonicos em um período de tempo mais curtos.

&nbsp;

------------------------------------------------------------------------

# Por que não usar uma regressão linear

Regressão linear presume que voce tem dados independentes e identicamente distribuidos(i.i.d). Contudo, em analise de series temporais isso não ocorre pois o pontos proximos no tempo costuman estar fortemente correlacionados uns com os outros, **quando não há correlações temporais os dados de series temporais dificilmente servem para tarefas tradicionais de series temporais:**

-   Predizer o futuro

-   Compreender a dinamica temporal

### Modelo Autorregressivos

Tem como base a intuiçao de que o passado prediz o futuro. Desse modo, ele pressupõe um processo de serie temporal no qual o valor em um ponto no tempo t é a função dos valores da série em pontos anteriores no tempo.

#### Escolhendo os parametros para um modelo AR

```{r}
path_ = "C:\\Users\\mateu\\Documents\\MEGA\\Projetos-git\\analise-pratica-series-temporais_predicao-stats-ml\\capitulo-6\\datasets\\Daily_Demand_Forecasting_Orders.csv"

data = read.csv(path_, header = TRUE, sep = ",")

head( x = data, n = 5)
```

```{r}
plot(data$Banking.orders..2., type = 'l')
```

```{r}
pacf(x = data$Banking.orders..2.)
```

```{r}
fit_ = ar( data$Banking.orders..2., method = "mle")
fit_
```

```{r}
est = arima(x = data$Banking.orders..2., order = c(3, 0, 0))
est
```

> O parâmetro `order` em um modelo ARIMA especifica a estrutura do modelo através de três componentes: (p, d, q). No seu caso (3, 0, 0), você está ajustando um modelo AR(3).
>
> Vou explicar cada componente:
>
> 1.  **p = 3:** Ordem do componente autorregressivo (AR)
>
>     -   Indica quantos lags da série serão usados como preditores
>
>     -   No seu caso, AR(3) significa que o modelo usa os valores de t-1, t-2 e t-3 para prever t

```{r}
est.1 = arima(
  x = data$Banking.orders..2.,
  order = c(3, 0, 0),
  fixed = c(0, NA, NA, NA),
  transform.pars = FALSE
)

est.1
```

> Definimos o

```{r}
acf(est.1$residuals
    )
```

> Essa observação é útil para acreditarmos que nosso modelo é satisfatorio:
>
> -   Não vemos um padrão de autocorrelaçao entre os residuos, se tivessemos visto esse padrão provavelmente retornariamos ao nosso modelo original, considerando a inclusão de termo adicionais para acrescentar complexidade e explicar a autocorrelação significativa dos residuos

**Teste de ljung-box**

-   $H_0$ : Os dados não apresentam correlação serial

-   $H_a$ : Os dados apresentam correlação serial

    > Se aceitar $H_0$ tenho um modelos satisfatorio

```{r}
Box.test(
  est.1$residuals, lag = 10, type = "Ljung-Box", fitdf = 3
)
```

> 0.23 \> 0.01 : não rejeitamos $H_0$

#### Previsão com um processo AR(p)

1.  **Previsões um passo a frente :**
    -   Prever um passo a frente com um modelo AR

```{r}
plot(data$Banking.orders..2., type = "l")
lines(
  x = fitted(est.1), col = 3, lwd = 2
)
```

```{r}
cor(
 diff(data$Banking.orders..2.), diff(fitted(est.1)), 
)
```

```{r}
plot(diff(data$Banking.orders..2.), diff(fitted(est.1)))
```

```{r}
est.1
```

2.  **Previsão multipassos**

```{r}
a = forecast(est.1, h = 3)

```

```{r}
plot(a$fitted)
```

```{r}
```

```{r}
a.30_ = forecast(est.1, h = 30)
a.30_$fitted
```

```{r}
plot(a.30_$fitted)
```

> **Modelos AR, ARMA ARIMA sçao melhores para fazer previsão de curto prazo. Quando há grandes horizontes no futuro esses modelos perdem influencia preditiva**
